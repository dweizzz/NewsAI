[
  {
    "path": ".pytest_cache/.gitignore",
    "content": "# Created by pytest automatically.\n*\n"
  },
  {
    "path": ".pytest_cache/CACHEDIR.TAG",
    "content": "Signature: 8a477f597d28d172789f06886806bc55\n# This file is a cache directory tag created by pytest.\n# For information about cache directory tags, see:\n#\thttps://bford.info/cachedir/spec.html\n"
  },
  {
    "path": ".pytest_cache/README.md",
    "content": "# pytest cache directory #\n\nThis directory contains data from the pytest's cache plugin,\nwhich provides the `--lf` and `--ff` options, as well as the `cache` fixture.\n\n**Do not** commit this to version control.\n\nSee [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.\n"
  },
  {
    "path": ".pytest_cache/v/cache/lastfailed",
    "content": "{\n  \"tests/test_api.py::test_invalid_search_term\": true,\n  \"tests/test_auth.py::test_create_user\": true,\n  \"tests/test_auth.py::test_create_user_duplicate_email\": true,\n  \"tests/test_auth.py::test_login_success\": true,\n  \"tests/test_auth.py::test_login_wrong_password\": true,\n  \"tests/test_auth.py::test_get_current_user\": true,\n  \"tests/test_auth.py::test_get_current_user_invalid_token\": true,\n  \"tests/test_search_topics.py::test_create_search_topic\": true,\n  \"tests/test_search_topics.py::test_get_user_search_topics\": true,\n  \"tests/test_search_topics.py::test_delete_search_topic\": true,\n  \"tests/test_search_topics.py::test_delete_search_topic_unauthorized\": true,\n  \"tests/test_search_topics.py::test_delete_nonexistent_search_topic\": true\n}"
  },
  {
    "path": ".pytest_cache/v/cache/nodeids",
    "content": "[\n  \"tests/test_api.py::test_get_insights\",\n  \"tests/test_api.py::test_health_check\",\n  \"tests/test_api.py::test_invalid_search_term\",\n  \"tests/test_auth.py::test_create_user\",\n  \"tests/test_auth.py::test_create_user_duplicate_email\",\n  \"tests/test_auth.py::test_get_current_user\",\n  \"tests/test_auth.py::test_get_current_user_invalid_token\",\n  \"tests/test_auth.py::test_login_success\",\n  \"tests/test_auth.py::test_login_wrong_password\",\n  \"tests/test_search_topics.py::test_create_search_topic\",\n  \"tests/test_search_topics.py::test_create_search_topic_unauthorized\",\n  \"tests/test_search_topics.py::test_delete_nonexistent_search_topic\",\n  \"tests/test_search_topics.py::test_delete_search_topic\",\n  \"tests/test_search_topics.py::test_delete_search_topic_unauthorized\",\n  \"tests/test_search_topics.py::test_get_user_search_topics\",\n  \"tests/test_search_topics.py::test_get_user_search_topics_unauthorized\"\n]"
  },
  {
    "path": ".pytest_cache/v/cache/stepwise",
    "content": "[]"
  },
  {
    "path": "alembic.ini",
    "content": "[alembic]\nscript_location = alembic\nsqlalchemy.url = sqlite:///./newsai.db\n\n[loggers]\nkeys = root,sqlalchemy,alembic\n\n[handlers]\nkeys = console\n\n[formatters]\nkeys = generic\n\n[logger_root]\nlevel = WARN\nhandlers = console\nqualname =\n\n[logger_sqlalchemy]\nlevel = WARN\nhandlers =\nqualname = sqlalchemy.engine\n\n[logger_alembic]\nlevel = INFO\nhandlers =\nqualname = alembic\n\n[handler_console]\nclass = StreamHandler\nargs = (sys.stderr,)\nlevel = NOTSET\nformatter = generic\n\n[formatter_generic]\nformat = %(levelname)-5.5s [%(name)s] %(message)s\ndatefmt = %H:%M:%S "
  },
  {
    "path": "app/__init__.py",
    "content": "\"\"\"\nNews AI application package.\n\"\"\" "
  },
  {
    "path": "app/database/__init__.py",
    "content": "from .config import Base, get_db, engine\nfrom .models import User, SearchTerm\n\n__all__ = [\"Base\", \"get_db\", \"engine\", \"User\", \"SearchTerm\"] "
  },
  {
    "path": "app/database/config.py",
    "content": "from sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\n# Get database URL from environment variable, default to SQLite for development\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./newsai.db\")\n\n# Create SQLAlchemy engine\nengine = create_engine(\n    DATABASE_URL,\n    # Required for SQLite\n    connect_args={\"check_same_thread\": False} if DATABASE_URL.startswith(\"sqlite\") else {}\n)\n\n# Create SessionLocal class\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# Create Base class\nBase = declarative_base()\n\n# Dependency to get DB session\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close() "
  },
  {
    "path": "app/database/models.py",
    "content": "from sqlalchemy import Boolean, Column, Integer, String, DateTime, ForeignKey\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\nfrom .config import Base\n\nclass User(Base):\n    __tablename__ = \"users\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    email = Column(String, unique=True, index=True, nullable=False)\n    username = Column(String, unique=True, index=True, nullable=False)\n    hashed_password = Column(String, nullable=False)\n    is_active = Column(Boolean, default=True)\n    is_superuser = Column(Boolean, default=False)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n\n    # Relationship to search terms\n    search_terms = relationship(\"SearchTerm\", back_populates=\"user\", cascade=\"all, delete-orphan\")\n\nclass SearchTerm(Base):\n    __tablename__ = \"search_terms\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    term = Column(String, nullable=False)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n\n    # Relationship to user\n    user = relationship(\"User\", back_populates=\"search_terms\") "
  },
  {
    "path": "app/main.py",
    "content": "from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom typing import List, Dict, Any\nfrom .utils.summarize import get_news_insights\nfrom .routers import auth, search_terms\n\napp = FastAPI(title=\"News AI API\")\n\n# Configure CORS\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:5173\"],  # Vite's default port\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(auth.router)\napp.include_router(search_terms.router)\n\nclass SearchRequest(BaseModel):\n    search_term: str\n    num_results: int = 5\n\nclass Insight(BaseModel):\n    insight: str\n    source_title: str\n    source_link: str\n\n@app.post(\"/api/insights\", response_model=List[Insight])\nasync def get_insights(request: SearchRequest):\n    try:\n        insights = get_news_insights(request.search_term, request.num_results)\n        if not insights:\n            raise HTTPException(status_code=404, detail=\"No insights found\")\n        return insights\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/api/health\")\nasync def health_check():\n    return {\"status\": \"healthy\"} "
  },
  {
    "path": "app/routers/__init__.py",
    "content": "from . import auth\n\n__all__ = [\"auth\"] "
  },
  {
    "path": "app/routers/auth.py",
    "content": "from fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordRequestForm\nfrom sqlalchemy.orm import Session\nfrom pydantic import ValidationError\nfrom ..database.config import get_db\nfrom ..schemas.auth import Token, UserRegister\nfrom ..services.user_service import authenticate_user, create_user\nfrom ..utils.security import create_access_token\nfrom datetime import timedelta\n\nrouter = APIRouter(prefix=\"/auth\", tags=[\"authentication\"])\n\n@router.post(\"/register\", response_model=Token)\nasync def register(user_data: UserRegister, db: Session = Depends(get_db)):\n    \"\"\"Register a new user.\"\"\"\n    try:\n        # Add detailed logging\n        print(f\"Registration attempt with email: {user_data.email}, username: {user_data.username}\")\n\n        user = create_user(\n            db=db,\n            email=user_data.email,\n            username=user_data.username,\n            password=user_data.password\n        )\n\n        # Create access token\n        access_token = create_access_token(\n            data={\"sub\": user.email}\n        )\n\n        return {\"access_token\": access_token, \"token_type\": \"bearer\"}\n\n    except ValidationError as e:\n        print(f\"Validation error: {e}\")\n        raise HTTPException(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail=str(e)\n        )\n    except HTTPException as e:\n        print(f\"HTTP error: {e.detail}\")\n        raise e\n    except Exception as e:\n        print(f\"Unexpected error: {str(e)}\")\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=str(e)\n        )\n\n@router.post(\"/login\", response_model=Token)\nasync def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_db)):\n    \"\"\"Login for access token.\"\"\"\n    user = authenticate_user(db, form_data.username, form_data.password)\n    if not user:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect email or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n\n    access_token = create_access_token(\n        data={\"sub\": user.email}\n    )\n\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}"
  },
  {
    "path": "app/routers/search_terms.py",
    "content": "from fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.orm import Session\nfrom typing import List\nfrom ..database.config import get_db\nfrom ..schemas.search_term import SearchTerm, SearchTermCreate\nfrom ..services.search_term_service import get_user_search_terms, create_search_term\nfrom ..utils.security import get_current_user\nfrom ..database.models import User\n\nrouter = APIRouter(prefix=\"/search-terms\", tags=[\"search terms\"])\n\n@router.get(\"/\", response_model=List[SearchTerm])\nasync def read_user_search_terms(\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    Get all search terms for the currently logged in user.\n    Requires authentication.\n    \"\"\"\n    search_terms = get_user_search_terms(db, current_user.id)\n    return search_terms\n\n@router.post(\"/\", response_model=SearchTerm)\nasync def create_user_search_term(\n    search_term: SearchTermCreate,\n    current_user: User = Depends(get_current_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"\n    Create a new search term for the currently logged in user.\n    Requires authentication.\n    \"\"\"\n    return create_search_term(db, current_user.id, search_term.term) "
  },
  {
    "path": "app/schemas/auth.py",
    "content": "from pydantic import BaseModel, EmailStr\n\nclass Token(BaseModel):\n    access_token: str\n    token_type: str\n\nclass TokenData(BaseModel):\n    username: str | None = None\n\nclass UserLogin(BaseModel):\n    email: EmailStr\n    password: str\n\nclass UserRegister(BaseModel):\n    email: EmailStr\n    username: str\n    password: str "
  },
  {
    "path": "app/schemas/search_term.py",
    "content": "from pydantic import BaseModel\nfrom datetime import datetime\n\nclass SearchTermBase(BaseModel):\n    term: str\n\nclass SearchTermCreate(SearchTermBase):\n    pass\n\nclass SearchTerm(SearchTermBase):\n    id: int\n    user_id: int\n    created_at: datetime\n\n    class Config:\n        from_attributes = True "
  },
  {
    "path": "app/services/search_term_service.py",
    "content": "from sqlalchemy.orm import Session\nfrom ..database.models import SearchTerm\nfrom typing import List\n\ndef get_user_search_terms(db: Session, user_id: int) -> List[SearchTerm]:\n    \"\"\"Get all search terms for a specific user.\"\"\"\n    return db.query(SearchTerm)\\\n        .filter(SearchTerm.user_id == user_id)\\\n        .order_by(SearchTerm.created_at.desc())\\\n        .all()\n\ndef create_search_term(db: Session, user_id: int, term: str) -> SearchTerm:\n    \"\"\"Create a new search term for a user.\"\"\"\n    db_search_term = SearchTerm(\n        term=term,\n        user_id=user_id\n    )\n    \n    db.add(db_search_term)\n    db.commit()\n    db.refresh(db_search_term)\n    \n    return db_search_term "
  },
  {
    "path": "app/services/user_service.py",
    "content": "from sqlalchemy.orm import Session\nfrom ..database.models import User\nfrom ..utils.security import get_password_hash, verify_password\nfrom fastapi import HTTPException\n\ndef get_user_by_email(db: Session, email: str) -> User | None:\n    \"\"\"Get a user by email.\"\"\"\n    return db.query(User).filter(User.email == email).first()\n\ndef get_user_by_username(db: Session, username: str) -> User | None:\n    \"\"\"Get a user by username.\"\"\"\n    return db.query(User).filter(User.username == username).first()\n\ndef create_user(db: Session, email: str, username: str, password: str) -> User:\n    \"\"\"Create a new user.\"\"\"\n    # Check if email already exists\n    if get_user_by_email(db, email):\n        raise HTTPException(status_code=400, detail=\"Email already registered\")\n    \n    # Check if username already exists\n    if get_user_by_username(db, username):\n        raise HTTPException(status_code=400, detail=\"Username already taken\")\n    \n    # Create new user\n    hashed_password = get_password_hash(password)\n    db_user = User(\n        email=email,\n        username=username,\n        hashed_password=hashed_password\n    )\n    \n    db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    \n    return db_user\n\ndef authenticate_user(db: Session, email: str, password: str) -> User | None:\n    \"\"\"Authenticate a user.\"\"\"\n    user = get_user_by_email(db, email)\n    if not user:\n        return None\n    if not verify_password(password, user.hashed_password):\n        return None\n    return user "
  },
  {
    "path": "app/utils/__init__.py",
    "content": "from .fetch_google_results import fetch_google_search_results\nfrom .summarize import get_news_insights, summarize_with_openai\n\n__all__ = [\"fetch_google_search_results\", \"get_news_insights\", \"summarize_with_openai\"] "
  },
  {
    "path": "app/utils/fetch_google_results.py",
    "content": "import os\nfrom dotenv import load_dotenv\nimport requests\nfrom typing import List, Dict, Any\n\n# Load environment variables\nload_dotenv()\n\ndef fetch_google_search_results(search_term: str, num_results: int = 10) -> List[Dict[str, Any]]:\n    \"\"\"\n    Fetch search results from Google using the Custom Search API.\n    \n    Args:\n        search_term (str): The search query\n        num_results (int): Number of results to return (max 10 per request)\n    \n    Returns:\n        List[Dict[str, Any]]: List of search results with title, link, and snippet\n    \"\"\"\n    api_key = os.getenv('GOOGLE_API_KEY')\n    cse_id = os.getenv('GOOGLE_CSE_ID')\n    \n    if not api_key or not cse_id:\n        raise ValueError(\"API key or Custom Search Engine ID not found in environment variables\")\n\n    full_search_term = f\"Recent news about {search_term}\"\n    \n    base_url = \"https://www.googleapis.com/customsearch/v1\"\n    params = {\n        'key': api_key,\n        'cx': cse_id,\n        'q': full_search_term,\n        'num': min(num_results, 10),  # Google API limits to 10 results per request\n        'sort': 'date'  # Sort by date to get recent results\n    }\n    \n    try:\n        response = requests.get(base_url, params=params)\n        response.raise_for_status()\n        data = response.json()\n        \n        if 'items' not in data:\n            return []\n            \n        return [{\n            'title': item.get('title', ''),\n            'link': item.get('link', ''),\n            'snippet': item.get('snippet', ''),\n            'date': item.get('pagemap', {}).get('metatags', [{}])[0].get('article:published_time', '')\n        } for item in data['items']]\n        \n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching search results: {e}\")\n        return [] "
  },
  {
    "path": "app/utils/security.py",
    "content": "from datetime import datetime, timedelta\nfrom typing import Optional\nfrom passlib.context import CryptContext\nfrom jose import JWTError, jwt\nimport os\nfrom dotenv import load_dotenv\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordBearer\nfrom sqlalchemy.orm import Session\nfrom ..database.config import get_db\n\n# Load environment variables\nload_dotenv()\n\n# JWT Configuration\nSECRET_KEY = os.getenv(\"JWT_SECRET_KEY\", \"your-secret-key-for-development\")\nALGORITHM = \"HS256\"\nACCESS_TOKEN_EXPIRE_MINUTES = 30\n\n# Update the password context configuration\npwd_context = CryptContext(\n    schemes=[\"bcrypt\"],\n    deprecated=\"auto\",\n    bcrypt__rounds=12  # Add explicit rounds\n)\n\n# OAuth2 scheme for token\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"auth/login\")\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify a password against its hash.\"\"\"\n    return pwd_context.verify(plain_password, hashed_password)\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Generate password hash.\"\"\"\n    return pwd_context.hash(password)\n\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:\n    \"\"\"Create a JWT access token.\"\"\"\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.utcnow() + expires_delta\n    else:\n        expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)\n    \n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\n    return encoded_jwt \n\nasync def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(get_db)):\n    \"\"\"\n    Get the current user from the JWT token.\n    This function will be used as a dependency in protected endpoints.\n    \"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    \n    try:\n        # Decode JWT token\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n        email: str = payload.get(\"sub\")\n        if email is None:\n            raise credentials_exception\n    except JWTError:\n        raise credentials_exception\n        \n    from ..services.user_service import get_user_by_email  # Import here to avoid circular import\n    # Get user from database\n    user = get_user_by_email(db, email)\n    if user is None:\n        raise credentials_exception\n        \n    return user "
  },
  {
    "path": "app/utils/summarize.py",
    "content": "import os\nfrom dotenv import load_dotenv\nimport openai\nfrom typing import List, Dict, Any\nfrom .fetch_google_results import fetch_google_search_results\nimport json\n\n# Load environment variables\nload_dotenv()\n\ndef summarize_with_openai(articles: List[Dict[str, Any]], search_term: str) -> List[Dict[str, Any]]:\n    \"\"\"\n    Use OpenAI to extract individual insights from articles.\n    \n    Args:\n        articles (List[Dict[str, Any]]): List of articles with title, link, snippet, and date\n        search_term (str): The search term used to find the articles\n    \n    Returns:\n        List[Dict[str, Any]]: List of insights with their sources\n    \"\"\"\n    openai.api_key = os.getenv('OPENAI_API_KEY')\n    \n    if not openai.api_key:\n        raise ValueError(\"OpenAI API key not found in environment variables\")\n    \n    # Prepare the content for analysis\n    content = f\"Here are recent news articles about '{search_term}':\\n\\n\"\n    for i, article in enumerate(articles):\n        content += f\"Article {i+1}:\\n\"\n        content += f\"Title: {article['title']}\\n\"\n        content += f\"Summary: {article['snippet']}\\n\"\n        if article.get('date'):\n            content += f\"Date: {article['date']}\\n\"\n        content += f\"Link: {article['link']}\\n\\n\"\n    \n    try:\n        response = openai.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"\"\"You are a precise data extraction assistant. Your task is to extract individual insights from news articles and format them as a JSON array.\n\nIMPORTANT: Your response must be a valid JSON array containing objects. Each object must have exactly these fields:\n- insight: A clear, concise statement of one specific fact or development\n- source_title: The title of the source article\n- source_link: The URL of the source article\n\nExample format:\n[\n  {\n    \"insight\": \"OpenAI released GPT-4 with improved capabilities\",\n    \"source_title\": \"OpenAI Announces GPT-4\",\n    \"source_link\": \"https://example.com/article1\"\n  },\n  {\n    \"insight\": \"Google's AI model achieved 90% accuracy in medical diagnosis\",\n    \"source_title\": \"Google AI Breakthrough in Healthcare\",\n    \"source_link\": \"https://example.com/article2\"\n  }\n]\n\nGuidelines:\n1. Extract specific, factual insights\n2. Include source information for each insight\n3. Ensure each insight is unique\n4. Focus on recent developments\n5. Keep insights concise and clear\"\"\"},\n                {\"role\": \"user\", \"content\": f\"Please extract individual insights from these news articles about {search_term} and format them as a JSON array:\\n\\n{content}\"}\n            ],\n            max_tokens=1000,\n            temperature=0.3  # Lower temperature for more consistent, factual output\n        )\n        \n        # Get the response content\n        response_content = response.choices[0].message.content.strip()\n        \n        # Try to parse the JSON response\n        try:\n            insights = json.loads(response_content)\n        except json.JSONDecodeError as e:\n            print(f\"Error parsing JSON response: {e}\")\n            print(\"Raw response:\", response_content)\n            return []\n            \n        # Validate the structure\n        if not isinstance(insights, list):\n            print(\"Error: Response is not a JSON array\")\n            return []\n            \n        # Validate each insight has required fields\n        valid_insights = []\n        for insight in insights:\n            if all(key in insight for key in ['insight', 'source_title', 'source_link']):\n                valid_insights.append(insight)\n            else:\n                print(f\"Warning: Skipping invalid insight structure: {insight}\")\n                \n        return valid_insights\n        \n    except Exception as e:\n        print(f\"Error generating insights: {e}\")\n        return []\n\ndef get_news_insights(search_term: str, num_results: int = 5) -> List[Dict[str, Any]]:\n    \"\"\"\n    Main function to fetch news and generate structured insights.\n    \n    Args:\n        search_term (str): The search term to find news about\n        num_results (int): Number of articles to fetch and analyze\n    \n    Returns:\n        List[Dict[str, Any]]: List of insights with their sources\n    \"\"\"\n    # Fetch search results\n    results = fetch_google_search_results(search_term, num_results)\n    \n    if not results:\n        print(f\"No recent news found for '{search_term}'\")\n        return []\n    \n    # Generate insights using OpenAI\n    insights = summarize_with_openai(results, search_term)\n    \n    if not insights:\n        print(\"No valid insights were generated\")\n    \n    return insights "
  },
  {
    "path": "collect-files.js",
    "content": "const fs = require('fs');\nconst path = require('path');\n\n// Configuration\nconst ignoreDirs = ['node_modules', '.git', 'dist', 'build', 'coverage', 'tests', 'alembic', '__pycache__', 'migrations'];\nconst ignoreExts = ['.log', '.env', '.DS_Store', '.gitignore', '.pyc', '.pyo', '.pyd', '.pyw', '.pyz', '.pywz', '.pyzw', '.pyz', '.db'];\nconst maxFileSizeInBytes = 1024 * 1024; // 1MB limit per file\n\nfunction collectFiles(directory) {\n  const results = [];\n  \n  function scanDirectory(currentPath, relativePath = '') {\n    const files = fs.readdirSync(currentPath);\n    \n    for (const file of files) {\n      const fullPath = path.join(currentPath, file);\n      const stats = fs.statSync(fullPath);\n      const relPath = path.join(relativePath, file);\n      \n      if (stats.isDirectory()) {\n        if (!ignoreDirs.includes(file)) {\n          scanDirectory(fullPath, relPath);\n        }\n      } else {\n        const ext = path.extname(file);\n        if (!ignoreExts.includes(ext) && stats.size <= maxFileSizeInBytes) {\n          try {\n            const content = fs.readFileSync(fullPath, 'utf8');\n            results.push({\n              path: relPath,\n              content\n            });\n          } catch (err) {\n            console.error(`Error reading file ${fullPath}: ${err.message}`);\n          }\n        }\n      }\n    }\n  }\n  \n  scanDirectory(directory);\n  return results;\n}\n\n// Get the current directory\nconst rootDir = process.cwd();\nconst files = collectFiles(rootDir);\n\n// Save results to a JSON file\nconst outputFile = path.join(rootDir, 'backend-files.json');\nfs.writeFileSync(outputFile, JSON.stringify(files, null, 2));\n\nconsole.log(`Collected ${files.length} files. Results saved to ${outputFile}`);"
  },
  {
    "path": "pyproject.toml",
    "content": "[tool.pytest.ini_options]\npythonpath = [\n    \".\"\n]\n\n[tool.alembic]\nscript_location = alembic\nsqlalchemy.url = sqlite:///./newsai.db "
  },
  {
    "path": "requirements.txt",
    "content": "python-dotenv==1.0.0\nrequests==2.31.0\nopenai==1.12.0\nfastapi==0.110.0\nuvicorn==0.27.1\npydantic==2.6.3\npytest==8.0.2\nhttpx==0.27.0\nsqlalchemy==2.0.27\nalembic==1.13.1\npsycopg2-binary==2.9.9\nemail-validator==2.1.0\npython-jose[cryptography]==3.3.0\nbcrypt==4.0.1\npasslib[bcrypt]>=1.7.4\npython-multipart==0.0.9 \npymongo==4.11.0"
  }
]